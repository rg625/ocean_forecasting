{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from models.autoencoder import KoopmanAutoencoder\n",
    "from models.utils import load_checkpoint, load_config, get_dataset_class_and_kwargs, load_datasets\n",
    "from models.dataloader import create_dataloaders\n",
    "from models.metrics import Metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"path/to/your/config.yaml\"  # Update this path\n",
    "CKPT_PATH = None  # Set to specific checkpoint if needed, otherwise loads best/final\n",
    "\n",
    "ROLL_OUT_STEPS = 40  # Number of future time steps to predict\n",
    "VISUALIZE = True     # Toggle to show visualizations\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(CONFIG_PATH)\n",
    "config['training']['use_checkpoint'] = False  # Don't checkpoint during testing\n",
    "\n",
    "dataset_class, dataset_kwargs = get_dataset_class_and_kwargs(config)\n",
    "_, _, test_dataset = load_datasets(config, dataset_class, dataset_kwargs)\n",
    "_, _, test_loader = create_dataloaders(\n",
    "    train_dataset=None,\n",
    "    val_dataset=None,\n",
    "    test_dataset=test_dataset,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Load Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KoopmanAutoencoder(\n",
    "    input_frames=config[\"data\"][\"input_sequence_length\"],\n",
    "    input_channels=config[\"model\"][\"input_channels\"],\n",
    "    height=config[\"model\"][\"height\"],\n",
    "    width=config[\"model\"][\"width\"],\n",
    "    latent_dim=config[\"model\"][\"latent_dim\"],\n",
    "    hidden_dims=config[\"model\"][\"hidden_dims\"],\n",
    "    use_checkpoint=False,\n",
    "    **config[\"model\"][\"conv_kwargs\"]\n",
    ").to(DEVICE)\n",
    "\n",
    "if CKPT_PATH is not None:\n",
    "    print(f\"Loading from checkpoint: {CKPT_PATH}\")\n",
    "    model, _, _, _ = load_checkpoint(CKPT_PATH, model=model, optimizer=None)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Run Rollout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_long_rollout(model, input_seq, rollout_steps):\n",
    "    input_seq = input_seq.unsqueeze(0).to(DEVICE)  # [1, T, C, H, W]\n",
    "    preds = [input_seq[:, i] for i in range(input_seq.size(1))]  # initial context\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(rollout_steps):\n",
    "            context = torch.stack(preds[-config[\"data\"][\"input_sequence_length\"]:], dim=1)  # sliding window\n",
    "            pred = model.predict(context)  # [B, C, H, W]\n",
    "            preds.append(pred)\n",
    "\n",
    "    return torch.stack(preds, dim=1).squeeze(0).cpu()  # [T+rollout_steps, C, H, W]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Visualize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = test_dataset[0]  # [T, C, H, W]\n",
    "input_seq = sample[:config[\"data\"][\"input_sequence_length\"]]\n",
    "ground_truth = sample[:config[\"data\"][\"input_sequence_length\"] + ROLL_OUT_STEPS]\n",
    "\n",
    "predicted_seq = run_long_rollout(model, input_seq, ROLL_OUT_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Plot Results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rollout(gt, pred, variable_idx=0, frame_stride=5):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    num_plots = min(gt.size(0), pred.size(0), 10)\n",
    "    for i in range(num_plots):\n",
    "        plt.subplot(2, num_plots, i+1)\n",
    "        plt.imshow(gt[i, variable_idx], cmap='viridis')\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(\"Ground Truth\")\n",
    "\n",
    "        plt.subplot(2, num_plots, num_plots+i+1)\n",
    "        plt.imshow(pred[i, variable_idx], cmap='viridis')\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(\"Prediction\")\n",
    "\n",
    "    plt.suptitle(\"Koopman AE: Ground Truth vs Prediction (Long Rollout)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if VISUALIZE:\n",
    "    plot_rollout(ground_truth, predicted_seq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = Metric(\n",
    "    mode=config[\"metric\"][\"type\"],\n",
    "    variable_mode=config[\"metric\"][\"variable_mode\"]\n",
    ")\n",
    "\n",
    "loss = metric(predicted_seq[:ground_truth.shape[0]], ground_truth)\n",
    "print(f\"\\nLong Rollout {config['metric']['type']} Metric: {loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samudra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
